- hosts: k8s-master
  become: yes
  roles:
    - role: deploy-k8s-cluster-with-kubeadm
      k8s_role_to_deploy:
        - master
  tasks:
    - name: get kubeadm join command
      shell: kubeadm token create --print-join-command
      register: kubeadm_join_cmd

- hosts: k8s-nodes
  become: yes
  roles:
    - role: deploy-k8s-cluster-with-kubeadm
      k8s_role_to_deploy:
        - node
      kubeadm_join_cmd: "{{ hostvars['k8s-master']['kubeadm_join_cmd']['stdout'] }}"

- hosts: k8s-master
  become: yes
  tasks:
    - name: label k8s nodes for insulating system and workload pods
      shell: |
          set -ex
          sleep 10
          kubectl get nodes
          kubectl wait --timeout 300s --for condition=ready node --all
          kubectl label node k8s-master env=system
          for node in "{{ groups['k8s-nodes']|join(' ') }}"; do
              kubectl label node ${node} env=workload
          done
      args:
        executable: /bin/bash

    - name: prepare k8s namespaces for kubeflow and TFjobs
      when: run_kubeflow_tfbenchmarks|default(false)|bool
      shell:
        cmd: |
          set -ex
          cat <<EOF | kubectl create -f -
          apiVersion: v1
          kind: Namespace
          metadata:
           name: kubeflow
           annotations:
             scheduler.alpha.kubernetes.io/node-selector: env=system
          spec: {}
          status: {}
          EOF

          cat <<EOF | kubectl create -f -
          apiVersion: v1
          kind: Namespace
          metadata:
           name: kf-tfbenchmarks
           annotations:
             scheduler.alpha.kubernetes.io/node-selector: env=workload
          spec: {}
          status: {}
          EOF
          CURRENT_CONTEXT=$(kubectl config current-context)
          CURRENT_CLUSTER=$(kubectl config get-contexts $CURRENT_CONTEXT | tail -1 | awk '{print $3}')
          CURRENT_USER=$(kubectl config get-contexts $CURRENT_CONTEXT | tail -1 | awk '{print $4}')
          kubectl config set-context kf-tfbenchmarks \
            --namespace kf-tfbenchmarks \
            --cluster $CURRENT_CLUSTER \
            --user $CURRENT_USER
          sed -i '/--enable-admission-plugins/ s/$/,PodNodeSelector/' /etc/kubernetes/manifests/kube-apiserver.yaml
          sleep 30
        executable: /bin/bash

    - name: prepare k8s namespaces for volcano and TFjobs
      when: run_volcano_tfbenchmarks|default(false)|bool
      shell:
        cmd: |
          set -ex
          cat <<EOF | kubectl create -f -
          apiVersion: v1
          kind: Namespace
          metadata:
           name: volcano
           annotations:
             scheduler.alpha.kubernetes.io/node-selector: env=system
          spec: {}
          status: {}
          EOF

          cat <<EOF | kubectl create -f -
          apiVersion: v1
          kind: Namespace
          metadata:
           name: vc-tfbenchmarks
           annotations:
             scheduler.alpha.kubernetes.io/node-selector: env=workload
          spec: {}
          status: {}
          EOF
          sed -i '/--enable-admission-plugins/ s/$/,PodNodeSelector/' /etc/kubernetes/manifests/kube-apiserver.yaml
          sleep 30
        executable: /bin/bash

    - name: config PVs for kubeflow deployment
      when: run_kubeflow_tfbenchmarks|default(false)|bool
      shell:
        cmd: |
          set -ex
          apt-get install -y nfs-server
          export KUBECONFIG=/etc/kubernetes/admin.conf
          for i in `seq 1 3`;do
              mkdir -p /nfs-data/kubeflow-pv$i
              echo "/nfs-data/kubeflow-pv$i *(rw,sync,no_root_squash,no_subtree_check)" >> /etc/exports
              systemctl restart nfs-kernel-server.service
              cat << EOF >> kubeflow-pv$i.yaml
              apiVersion: v1
              kind: PersistentVolume
              metadata:
                name: kubeflow-pv$i
              spec:
                capacity:
                  storage: 20Gi
                accessModes:
                  - ReadWriteOnce
                nfs:
                  server: {{ ansible_host }}
                  path: /nfs-data/kubeflow-pv$i
          EOF
              kubectl create -f kubeflow-pv$i.yaml
          done
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'

    - name: deploy kubeflow and run tensorflow benchmarks
      when: run_kubeflow_tfbenchmarks|default(false)|bool
      shell: |
        set -ex
        wget https://github.com/kubeflow/kubeflow/releases/download/v0.5.0/kfctl_v0.5.0_linux.tar.gz
        tar -zxvf kfctl_*.tar.gz -C /usr/local/bin/
        export KFAPP="kfapp"
        kfctl init ${KFAPP} -v v0.5.0
        pushd ${KFAPP}
        kfctl generate all -V
        kfctl apply all -V
        kubectl -n kubeflow get all -o wide
        popd
        # pushd ${KFAPP}
        # kfctl delete all --delete_storage
        # popd

        kubectl -n kubeflow wait --timeout 300s --for condition=ready pod --all

        wget https://github.com/ksonnet/ksonnet/releases/download/v0.13.1/ks_0.13.1_linux_amd64.tar.gz
        tar -zxvf ks_*.tar.gz
        cp ks_0.13.1_linux_amd64/ks /usr/local/bin/
        export CNN_JOB_NAME=tfcnnbenchmarks
        export KF_VERSION=v0.5.0
        export KF_ENV=default
        # workaround for API limit error of Github, see:
        # https://github.com/ksonnet/ksonnet/blob/master/docs/troubleshooting.md#github-rate-limiting-errors
        export GITHUB_TOKEN=c0250b662cfa40845058626ca47eb5accb586d27
        ks init ${CNN_JOB_NAME} --context kf-tfbenchmarks
        pushd ${CNN_JOB_NAME}
        ks registry add kubeflow github.com/kubeflow/kubeflow/tree/${KF_VERSION}/kubeflow
        ks pkg install kubeflow/examples
        ks prototype list
        for i in $(seq 1 3); do
            ks generate tf-job-simple-v1beta2 ${CNN_JOB_NAME}-${i} --name=${CNN_JOB_NAME}-${i}
        done
        sed -i 's/replicas: 1/replicas: 3/' components/tfcnnbenchmarks*

        ks apply ${KF_ENV}
        ks component list
        kubectl -n kf-tfbenchmarks get pods -o wide
        kubectl -n kf-tfbenchmarks get tfjobs -o wide

        function tfjobs_status() {
            kubectl -n kf-tfbenchmarks get tfjobs --no-headers | awk '{print $2}'|uniq
        }
        export -f tfjobs_status
        timeout 7200 bash -c '
            while :
            do
                job_status=$(tfjobs_status)
                if [[ ${job_status} == Running ]]; then
                    echo "Waiting for TF jobs running..."
                elif echo ${job_status} |grep Failed;
                    echo "Some TFjobs has failed :("
                    kubectl -n kf-tfbenchmarks get tfjobs -o wide
                    exit 1
                elif [[ ${job_status} == Succeeded ]]; then
                   echo "TFjobs running Succeeded :)"
                   kubectl -n kf-tfbenchmarks get tfjobs -o wide
                   break
                fi
                sleep 30
            done
            '

        mkdir -p '{{ ansible_user_dir }}/workspace/test_results/tfjobs/'
        job_pods = $(kubectl -n kf-tfbenchmarks get pods -o custom-columns=NAME:.metadata.name --no-headers |grep benchmark)
        for job_pod in ${job_pods}; do
            kubectl -n kf-tfbenchmarks logs ${job_pod} > "{{ ansible_user_dir }}/workspace/test_results/tfjobs/${job_pod}.log"
        done

        ks delete ${KF_ENV}
        popd
        rm -fr ${CNN_JOB_NAME}
      args:
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'

    - name: Deploy volcano and run tensorflow benchmarks
      when: run_volcano_tfbenchmarks|default(false)|bool
      shell: |
        set -ex
        mkdir -p $GOPATH/src/volcano.sh/
        git clone https://github.com/volcano-sh/volcano $GOPATH/src/volcano.sh/volcano
        pushd $GOPATH/src/volcano.sh/volcano
        curl -L https://git.io/get_helm.sh | bash
        helm init
        kubectl --namespace kube-system create serviceaccount tiller
        kubectl create clusterrolebinding tiller-cluster-rule \
         --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
        kubectl --namespace kube-system patch deploy tiller-deploy \
         -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}'

        sleep 30
        kubectl -n kube-system wait --timeout 300s --for condition=ready pod --all
        helm version
        helm plugin install installer/chart/volcano/plugins/gen-admission-secret
        helm gen-admission-secret --service volcano-trial-admission-service --namespace volcano
        helm install installer/chart/volcano --namespace volcano --name volcano-trial
        kubectl -n volcano get pods -o wide
        kubectl -n volcano get svc
        sleep 30
        kubectl -n volcano wait --timeout 300s --for condition=ready pod --all

        kubectl -n vc-tfbenchmarks create -f example/integrations/tensorflow/
        kubectl -n vc-tfbenchmarks get job.batch.volcano.sh
        sleep 10000000000

        function tfjobs_status() {
            kubectl -n vc-tfbenchmarks get job.batch.volcano.sh -o jsonpath='{.items[*].status.state.phase}'|uniq
        }
        export -f tfjobs_status

        timeout 7200 bash -c '
            while :
            do
                jobs_status = $(tfjobs_status)
                if [[ ${job_status} == Running ]]; then
                    echo "Waiting for TF jobs running..."
                elif echo ${job_status} |grep Failed;
                    echo "Some TFjobs has failed :("
                    kubectl -n vc-tfbenchmarks get job.batch.volcano.sh
                    exit 1
                elif [[ ${job_status} == Completed ]]; then
                   echo "TFjobs running Succeeded :)"
                   kubectl -n vc-tfbenchmarks get job.batch.volcano.sh
                   break
                fi
                sleep 30
            done
            '
        mkdir -p '{{ ansible_user_dir }}/workspace/test_results/tfjobs/'
        job_pods = $(kubectl -n vc-tfbenchmarks get pods -o custom-columns=NAME:.metadata.name --no-headers |grep benchmark)
        for job_pod in ${job_pods}; do
            kubectl -n vc-tfbenchmarks logs ${job_pod} > "{{ ansible_user_dir }}/workspace/test_results/tfjobs/${job_pod}.log"
        done

        kubectl -n vc-tfbenchmarks delete -f example/integrations/tensorflow/
        helm delete integration --purge
      args:
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
