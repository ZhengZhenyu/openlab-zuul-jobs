- name: Set up Kubernetes local cluster
  hosts: all
  roles:
    - export-vexxhost-openrc
  become: yes
  tasks:
    - name: Set up Kubernetes local cluster
      shell:
        cmd: |
          set -x
          # set -e
          # set -o pipefail

          apt-get install python-pip -y
          pip install -U python-openstackclient

          # Create cloud-config
          mkdir -p /etc/kubernetes/
          cat << EOF >> /etc/kubernetes/cloud-config
          [Global]
          domain-name = $OS_USER_DOMAIN_NAME
          tenant-id = $OS_PROJECT_ID
          auth-url = $OS_AUTH_URL
          password = $OS_PASSWORD
          username = $OS_USERNAME
          region = $OS_REGION_NAME

          [BlockStorage]
          bs-version = v2
          ignore-volume-az = yes
          EOF

          # Go where we cloned kubernetes repository
          cd $GOPATH/src/k8s.io/kubernetes/
          export API_HOST_IP=$(ifconfig | awk '/^docker0/ {getline; print $2}' | awk -F ':' '{print $2}')
          export KUBELET_HOST="0.0.0.0"
          export ALLOW_SECURITY_CONTEXT=true
          export ENABLE_CRI=false
          export ENABLE_HOSTPATH_PROVISIONER=true
          export ENABLE_SINGLE_CA_SIGNER=true
          export KUBE_ENABLE_CLUSTER_DNS=false
          export LOG_LEVEL=4
          # We want to use the openstack cloud provider
          export CLOUD_PROVIDER=openstack
          # We want to run a separate cloud-controller-manager for openstack
          export EXTERNAL_CLOUD_PROVIDER=true
          # DO NOT change the location of the cloud-config file. It is important for the old cinder provider to work
          export CLOUD_CONFIG=/etc/kubernetes/cloud-config
          # Specify the OCCM binary
          export EXTERNAL_CLOUD_PROVIDER_BINARY='{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/openstack-cloud-controller-manager'

          # location of where the kubernetes processes log their output
          mkdir -p '{{ ansible_user_dir }}/workspace/logs/kubernetes'
          export LOG_DIR='{{ ansible_user_dir }}/workspace/logs/kubernetes'
          # We need this for one of the conformance tests
          export ALLOW_PRIVILEGED=true
          # Just kick off all the processes and drop down to the command line
          export ENABLE_DAEMON=true
          export HOSTNAME_OVERRIDE=$(curl http://169.254.169.254/openstack/latest/meta_data.json | python -c "import sys, json; print json.load(sys.stdin)['name']")
          export MAX_TIME_FOR_URL_API_SERVER=5

          # Requirements to deploy the csi cinder driver
          export FEATURE_GATES="CSIPersistentVolume=true,MountPropagation=true"
          export RUNTIME_CONFIG="storage.k8s.io/v1alpha1=true"

          # -E preserves the current env vars, but we need to special case PATH
          sudo -E PATH=$PATH SHELLOPTS=$SHELLOPTS ./hack/local-up-cluster.sh -O

          # nohup "{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/cinder-csi-plugin" \
          #       --log_dir=${LOG_DIR} \
          #       --v=10 \
          #       --cloud-config ${CLOUD_CONFIG} >"${LOG_DIR}/cinder-csi-plugin.log" 2>&1 &

          # set up the config we need for kubectl to work
          cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt
          cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt
          cluster/kubectl.sh config set-context local --cluster=local --user=myself
          cluster/kubectl.sh config use-context local

          # Hack for RBAC for all for the new cloud-controller process, we need to do better than this
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:default kube-system-cluster-admin-1 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:pvl-controller kube-system-cluster-admin-2 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-node-controller kube-system-cluster-admin-3 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-controller-manager kube-system-cluster-admin-4 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:shared-informers kube-system-cluster-admin-5 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:kube-controller-manager  kube-system-cluster-admin-6 --clusterrole cluster-admin

          # go get -u github.com/kubernetes-csi/drivers || true
          # pushd  ${GOPATH}/src/github.com/kubernetes-csi/drivers
          # go get -u github.com/golang/dep/cmd/dep
          # make cinder
          # cp ./_output/cinderplugin ./pkg/cinder/dockerfile/
          # docker build -t k8scsi/cinderplugin ./pkg/cinder/dockerfile/
          # docker images
          # popd

          INSTANCE_UUID=$(curl http://169.254.169.254/openstack/latest/meta_data.json | python -c "import sys, json; print json.load(sys.stdin)['uuid']")
          echo "$INSTANCE_UUID" > /var/lib/cloud/data/instance-id

          # go get github.com/rexray/gocsi
          # pushd ${GOPATH}/src/github.com/rexray/gocsi
          # make build
          # popd

          docker pull xiangxinyong/cinderplugin
          docker tag xiangxinyong/cinderplugin docker.io/k8scsi/cinderplugin
          sed -i 's|docker.io/k8scsi/csi-provisioner|quay.io/k8scsi/csi-provisioner:v0.2.0|g' '{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/manifests/cinder-csi-plugin/csi-provisioner-cinderplugin.yaml'
          sed -i 's|docker.io/k8scsi/csi-attacher|quay.io/k8scsi/csi-attacher:v0.2.0|g' '{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/manifests/cinder-csi-plugin/csi-attacher-cinderplugin.yaml'
          sed -i 's|docker.io/k8scsi/driver-registrar|quay.io/k8scsi/driver-registrar:v0.2.0|g' '{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/manifests/cinder-csi-plugin/csi-nodeplugin-cinderplugin.yaml'
          {
              cloud_cfg=$(base64 -w 0 ${CLOUD_CONFIG})
              sed "s/cloud.conf.*$/cloud.conf: $cloud_cfg/g" -i '{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/manifests/cinder-csi-plugin/csi-secret-cinderplugin.yaml'
          } > /dev/null 2>&1

          cluster/kubectl.sh create -f '{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/manifests/cinder-csi-plugin'
          cluster/kubectl.sh create -f '{{ ansible_user_dir }}/{{ zuul.project.src_dir }}/examples/cinder-csi-plugin/nginx.yaml'

          sleep 7200
        executable: /bin/bash
        chdir: '{{ zuul.project.src_dir }}'
      environment: '{{ golang_env | combine(vexxhost_openrc) }}'
