- name: Add server to inventory
  hosts: localhost
  become: yes
  tasks:
    - name: Add server to inventory
      add_host:
        name: "{{ server_name }}"
        ansible_host: "{{ server_ip }}"
        ansible_user: "ubuntu"
        ansible_ssh_private_key_file: "{{ key_file }}"
        ansible_python_interpreter: /usr/bin/python3

- name: Prepare for local cluster
  hosts: "{{ server_name }}"
  become: yes
  gather_facts: no
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          export OS_PROJECT_DOMAIN_ID=default
          export OS_REGION_NAME=RegionOne
          export OS_USER_DOMAIN_ID=default
          export OS_PROJECT_NAME=admin
          export OS_IDENTITY_API_VERSION=3
          export OS_PASSWORD=secretadmin
          export OS_AUTH_TYPE=password
          export OS_AUTH_URL="http://{{ devstack_ip }}/identity"
          export OS_USERNAME=admin
          export OS_TENANT_NAME=admin
          export OS_VOLUME_API_VERSION=2

          if [[ ! -d "/etc/kubernetes/" ]]; then
              sudo mkdir -p /etc/kubernetes/
          fi
          chown ubuntu /etc/kubernetes/

          cat << EOF >> /etc/kubernetes/cloud-config
          [Global]
          domain-id = default
          tenant-id = "{{ project_id }}"
          auth-url = ${OS_AUTH_URL}
          password = secretadmin
          username = admin
          region = RegionOne

          [LoadBalancer]
          floating-network-id = "{{ floating_network_id }}"
          subnet-id = "{{ subnet_id }}"

          [BlockStorage]
          bs-version = v2
          EOF
          apt-get install make -y
          pushd '{{ ansible_user_dir }}/src/github.com/liu-sheng/openstack-cloud-controller-manager'
          make depend
          make build
          popd
        executable: /bin/bash
      environment:
        GOPATH: '{{ ansible_user_dir }}'
        PATH: '{{ ansible_env.PATH }}:/usr/local/go/bin:{{ ansible_user_dir }}/bin'

- name: Set up local cluster
  hosts: "{{ server_name }}"
  become: yes
  gather_facts: no
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          # go where we cloned kubernetes repository
          cd $GOPATH/src/k8s.io/kubernetes/

          # we want to use the openstack cloud provider
          export CLOUD_PROVIDER=openstack
          # we want to run a separate cloud-controller-manager for openstack
          export EXTERNAL_CLOUD_PROVIDER=true
          # DO NOT change the location of the cloud-config file. It's important for the old cinder provider to work
          export CLOUD_CONFIG=/etc/kubernetes/cloud-config

          # Kill existing processes
          ps -ef | grep -i -e etcd -e hyperkube | grep -v grep | awk '{print $2}' | xargs sudo kill -9
          # Cleanup some directories just in case
          sudo rm -rf /var/lib/kubelet/*

          # location of where the kubernetes processes log their output
          export LOG_DIR=/opt/stack/logs/
          # We need this for one of the conformance tests
          export ALLOW_PRIVILEGED=true
          # Just kick off all the processes and drop down to the command line
          export ENABLE_DAEMON=true
          # We need the hostname to match the name of the vm started by openstack
          export HOSTNAME_OVERRIDE=$(hostname)

          # Add other paths we usually keep stuff in
          export PATH=$GOPATH/bin:${PATH}:/opt/stack/bin:

          # -E preserves the current env vars, but we need to special case PATH
          sudo -E PATH=$PATH ./hack/local-up-cluster.sh

          # sudo of local-up-cluster mucks with permissions
          sudo chmod -R 777 /home/ubuntu/.kube
          sudo chmod 777 /var/run/kubernetes/client-admin.key

          # set up the config we need for kubectl to work
          cluster/kubectl.sh config set-cluster local --server=https://localhost:6443 --certificate-authority=/var/run/kubernetes/server-ca.crt
          cluster/kubectl.sh config set-credentials myself --client-key=/var/run/kubernetes/client-admin.key --client-certificate=/var/run/kubernetes/client-admin.crt
          cluster/kubectl.sh config set-context local --cluster=local --user=myself
          cluster/kubectl.sh config use-context local

          # Hack for RBAC for all for the new cloud-controller process, we need to do better than this
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:default kube-system-cluster-admin-1 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:pvl-controller kube-system-cluster-admin-2 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-node-controller kube-system-cluster-admin-3 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:cloud-controller-manager kube-system-cluster-admin-4 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:serviceaccount:kube-system:shared-informers kube-system-cluster-admin-5 --clusterrole cluster-admin
          cluster/kubectl.sh create clusterrolebinding --user system:kube-controller-manager  kube-system-cluster-admin-6 --clusterrole cluster-admin

        executable: /bin/bash
      environment:
        GOPATH: '{{ ansible_user_dir }}'
        PATH: '{{ ansible_env.PATH }}:/usr/local/go/bin:{{ ansible_user_dir }}/bin'
